{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np  # Numerical computing\n",
    "import math  # Mathematical functions\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "\n",
    "import warnings  # Warning management\n",
    "\n",
    "from tqdm.notebook import tqdm  # Progress bar for notebooks\n",
    "\n",
    "import scipy.stats as ss  # Statistical functions\n",
    "from sklearn.decomposition import PCA  # Principal Component Analysis\n",
    "from sklearn.preprocessing import MinMaxScaler  # Data scaling\n",
    "from sklearn.model_selection import train_test_split  # Data splitting\n",
    "from sklearn.metrics import confusion_matrix  # Confusion matrix for evaluation\n",
    "from sklearn.metrics import mean_squared_error  # Mean squared error for evaluation\n",
    "\n",
    "import torch  # PyTorch deep learning library\n",
    "import torch.nn as nn  # Neural network modules\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Data loading and batching\n",
    "import torch.nn.functional as F  # Neural network functions\n",
    "\n",
    "from imblearn.over_sampling import SMOTE  # Oversampling for imbalanced data\n",
    "from itertools import product  # Iteration tools\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set seaborn style for plots\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/responses_.csv')\n",
    "\n",
    "# Convert data to float (this doesn't modify df in place, you need to reassign)\n",
    "df = df.astype('float') \n",
    "\n",
    "# Calculate the 'FI' feature by taking the ceiling of the median of 'FI1' to 'FI4'\n",
    "df['FI'] = np.ceil(df[['FI1', 'FI2', 'FI3', 'FI4']].median(axis=1).values).astype('float')\n",
    "\n",
    "# Subtract 1 from all values in the DataFrame \n",
    "df = df - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the 'FI' column\n",
    "plt.hist(df.FI)\n",
    "\n",
    "# Set x-axis ticks to be integers from 0 to 4\n",
    "plt.xticks([x for x in np.arange(0, 5)])  \n",
    "\n",
    "# Label the y-axis as 'Count'\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Label the x-axis as 'FI Classes'\n",
    "plt.xlabel('FI Classes')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix X by dropping the 'FI1', 'FI2', 'FI3', 'FI4', and 'FI' columns\n",
    "X = df.drop(['FI1', 'FI2', 'FI3', 'FI4', 'FI'], axis=1).values  \n",
    "\n",
    "# Create the target variable y by extracting the 'FI' column\n",
    "y = df['FI'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SMOTE oversampling technique\n",
    "sm = SMOTE(random_state=42, k_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to oversample the minority class in the dataset\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the resampled 'FI' classes\n",
    "plt.hist(y_res)\n",
    "\n",
    "# Set x-axis ticks to be integers from 0 to 4\n",
    "plt.xticks([x for x in np.arange(0, 5)]) \n",
    "\n",
    "# Label the y-axis as 'Count'\n",
    "plt.ylabel('Count')  \n",
    "\n",
    "# Label the x-axis as 'FI Classes'\n",
    "plt.xlabel('FI Classes')  \n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=21)  \n",
    "\n",
    "# Further split the testing set into validation and testing sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d823e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the training, validation, and testing sets\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_valid: {X_valid.shape}') \n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_valid: {y_valid.shape}') \n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets for training, validation, and testing\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid).float(), torch.from_numpy(y_valid).float())\n",
    "test_data = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float())\n",
    "\n",
    "# Create DataLoaders for batching and shuffling\n",
    "train_loader = DataLoader(train_data, shuffle=True)  # Shuffle training data\n",
    "valid_loader = DataLoader(valid_data, shuffle=True)  # Shuffle validation data\n",
    "test_loader = DataLoader(test_data)  # No need to shuffle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce241b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the device to be used for training (MPS, CUDA, or CPU)\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(y_res))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple feedforward neural network classifier.\n",
    "\n",
    "    Args:\n",
    "        drpt1 (float, optional): Dropout probability for the first dropout layer. Defaults to 0.2.\n",
    "        drpt2 (float, optional): Dropout probability for the second dropout layer. Defaults to 0.4.\n",
    "\n",
    "    Attributes:\n",
    "        linear1 (nn.Linear): First linear layer.\n",
    "        linear2 (nn.Linear): Second linear layer.\n",
    "        linear3 (nn.Linear): Third linear layer (output layer).\n",
    "        dropout1 (nn.Dropout): First dropout layer.\n",
    "        dropout2 (nn.Dropout): Second dropout layer.\n",
    "\n",
    "    Forward Pass:\n",
    "        1. Applies the first linear layer to the input and then a ReLU activation.\n",
    "        2. Applies the first dropout layer to the output of the previous step.\n",
    "        3. Applies the second linear layer and then a ReLU activation.\n",
    "        4. Applies the second dropout layer.\n",
    "        5. Applies the third linear layer (output) and a ReLU activation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The output tensor of the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, drpt1=0.2, drpt2=0.4):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(79, 79)  # First linear layer\n",
    "        self.linear2 = nn.Linear(79, 50)  # Second linear layer\n",
    "        self.linear3 = nn.Linear(50, len(set(y_res)))  # Output layer\n",
    "        self.dropout1 = nn.Dropout(p=drpt2)  # Dropout layer 1\n",
    "        self.dropout2 = nn.Dropout(p=drpt2)  # Dropout layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(F.relu(self.linear1(x)))  # Linear layer 1 + ReLU + Dropout\n",
    "        x = self.dropout2(F.relu(self.linear2(x)))  # Linear layer 2 + ReLU + Dropout\n",
    "        x = F.relu(self.linear3(x))  # Output layer + ReLU\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    \"\"\"Calculates the accuracy of the model's predictions.\n",
    "\n",
    "    Args:\n",
    "      out (torch.Tensor): The output tensor from the model.\n",
    "      labels (torch.Tensor): The true labels.\n",
    "\n",
    "    Returns:\n",
    "      int: The number of correct predictions.\n",
    "    \"\"\"\n",
    "    _, pred = torch.max(out, dim=1)  # Get the predicted class indices\n",
    "    return torch.sum(pred == labels).item()  # Count correct predictions and convert to Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier model\n",
    "model = ClassifierModel()\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 0.1, 0.1, 0.5, 0.2]))  \n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  \n",
    "\n",
    "# Print the model architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080abbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1  # Number of training epochs\n",
    "print_every = 10  # Print training progress every 10 epochs\n",
    "valid_loss_min = np.Inf  # Initialize minimum validation loss to infinity\n",
    "val_loss = []  # List to store validation losses\n",
    "val_acc = []  # List to store validation accuracies\n",
    "train_loss = []  # List to store training losses\n",
    "train_acc = []  # List to store training accuracies\n",
    "total_step = len(train_loader)  # Total number of batches in the training loader\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "    running_loss = 0.0  # Initialize running loss for the epoch\n",
    "    correct = 0  # Initialize correct predictions for the epoch\n",
    "    total = 0  # Initialize total samples for the epoch\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "\n",
    "    # Iterate over batches in the training loader\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        outputs = model(data_)  # Forward pass\n",
    "        loss = criterion(outputs, target_.long())  # Calculate loss\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update model weights\n",
    "        running_loss += loss.item()  # Accumulate running loss\n",
    "        _, pred = torch.max(outputs, dim=1)  # Get predicted class indices\n",
    "        correct += torch.sum(pred == target_).item()  # Count correct predictions\n",
    "        total += target_.size(0)  # Count total samples\n",
    "\n",
    "    train_acc.append(100 * correct / total)  # Calculate and store training accuracy\n",
    "    train_loss.append(running_loss / total_step)  # Calculate and store training loss\n",
    "\n",
    "    batch_loss = 0  # Initialize batch loss for validation\n",
    "    total_t = 0  # Initialize total samples for validation\n",
    "    correct_t = 0  # Initialize correct predictions for validation\n",
    "\n",
    "    # Validation loop (no gradients needed)\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        for data_t, target_t in (valid_loader):\n",
    "            outputs_t = model(data_t)  # Forward pass\n",
    "            loss_t = criterion(outputs_t, target_t.long())  # Calculate loss\n",
    "            batch_loss += loss_t.item()  # Accumulate batch loss\n",
    "            _, pred_t = torch.max(outputs_t, dim=1)  # Get predicted class indices\n",
    "            correct_t += torch.sum(pred_t == target_t).item()  # Count correct predictions\n",
    "            total_t += target_t.size(0)  # Count total samples\n",
    "\n",
    "        val_acc.append(100 * correct_t / total_t)  # Calculate and store validation accuracy\n",
    "        val_loss.append(batch_loss / len(valid_loader))  # Calculate and store validation loss\n",
    "        network_learned = batch_loss < valid_loss_min  # Check if validation loss improved\n",
    "\n",
    "        # Print validation progress\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "\n",
    "        # Save model if validation loss improved\n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(model.state_dict(), 'model_classification_tutorial.pt')\n",
    "            print('Detected network improvement, saving current model')\n",
    "\n",
    "    model.train()  # Set model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "plt.plot(train_loss, label='Training')\n",
    "plt.plot(val_loss, label='Validation')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.show()  # Add plt.show() to display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b04588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy curves\n",
    "plt.plot(train_acc, label='Training')\n",
    "plt.plot(val_acc, label='Validation')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.show()  # Add plt.show() to display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    batch_loss = 0  # Initialize batch loss for validation\n",
    "    total_t = 0  # Initialize total samples for validation\n",
    "    correct_t = 0  # Initialize correct predictions for validation\n",
    "\n",
    "    # Iterate over the validation data loader\n",
    "    for data_t, target_t in (valid_loader):\n",
    "        outputs_t = model(data_t)  # Forward pass\n",
    "        loss_t = criterion(outputs_t, target_t.long())  # Calculate the loss\n",
    "        batch_loss += loss_t.item()  # Accumulate batch loss\n",
    "        _, pred_t = torch.max(outputs_t, dim=1)  # Get the predicted class indices\n",
    "        correct_t += torch.sum(pred_t == target_t).item()  # Count correct predictions\n",
    "        total_t += target_t.size(0)  # Count total samples\n",
    "\n",
    "    val_acc.append(100 * correct_t / total_t)  # Calculate and store validation accuracy\n",
    "    val_loss.append(batch_loss / len(valid_loader))  # Calculate and store validation loss\n",
    "    network_learned = batch_loss < valid_loss_min  # Check if validation loss improved\n",
    "\n",
    "    # Print validation progress\n",
    "    print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "\n",
    "    # Save the best weight\n",
    "    if network_learned:\n",
    "        valid_loss_min = batch_loss\n",
    "        torch.save(model.state_dict(), 'model_classification_tutorial.pt')\n",
    "        print('Detected network improvement, saving current model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e48066",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vals = []  # List to store predicted values\n",
    "label_vals = []  # List to store true labels\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    # Iterate over the test data loader\n",
    "    for data_t, target_t in (test_loader):\n",
    "        outputs_t = model(data_t)  # Forward pass\n",
    "        _, pred_t = torch.max(outputs_t, dim=1)  # Get predicted class indices\n",
    "\n",
    "        # Assuming you want to store all predictions and labels (for multi-class)\n",
    "        preds_vals.extend(pred_t.tolist())  # Store all predicted values in the list\n",
    "        label_vals.extend(target_t.long().tolist())  # Store all true labels in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the predicted and true labels\n",
    "df_res = pd.DataFrame([preds_vals, label_vals]).T  \n",
    "df_res.columns = ['pred', 'true']  # Rename columns\n",
    "df_res = df_res + 1  # Add 1 to the predictions and true labels (potentially reversing the -1 done during preprocessing)\n",
    "df_res['correct'] = df_res['pred'] == df_res['true']  # Check for correct predictions\n",
    "df_res['correct'] = df_res['correct'].map({True: 1, False: 0})  # Convert boolean to integer (1 for correct, 0 for incorrect)\n",
    "df_res  # Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: {round(df_res.correct.sum()/len(df_res)*100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat = confusion_matrix(df_res.pred, df_res.true, labels=[1, 2, 3, 4, 5], normalize='true')\n",
    "vals = ['1', '2', '3', '4', '5']\n",
    "cmat = pd.DataFrame(c_mat, columns = vals, index=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bec8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cmat, annot=True, cmap='crest', \n",
    "                 cbar_kws={'label': 'Score'})\n",
    "\n",
    "ax.figure.axes[-1].yaxis.label.set_size(14)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batelec_env",
   "language": "python",
   "name": "batelec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
